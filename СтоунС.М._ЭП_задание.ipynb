{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: python-chess in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.999)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: zstandard in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: chess<2,>=1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-chess) (1.11.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy python-chess tqdm requests zstandard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess\n",
    "import chess.pgn\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zstandard as zstd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_chess_database():\n",
    "    \"\"\"\n",
    "    Загрузка базы данных шахматных партий\n",
    "    \"\"\"\n",
    "    url = \"https://database.lichess.org/standard/lichess_db_standard_rated_2013-01.pgn.zst\"\n",
    "    filename = \"lichess_db_standard_rated_2013-01.pgn.zst\"\n",
    "    \n",
    "    if not Path(filename).exists():\n",
    "        print(\"Загрузка базы данных...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(filename, 'wb') as f, tqdm(\n",
    "            desc=filename,\n",
    "            total=total_size,\n",
    "            unit='iB',\n",
    "            unit_scale=True\n",
    "        ) as pbar:\n",
    "            for data in response.iter_content(chunk_size=1024):\n",
    "                size = f.write(data)\n",
    "                pbar.update(size)\n",
    "    else:\n",
    "        print(\"База данных уже загружена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(base_path=\"preprocessed_data\"):\n",
    "    \"\"\"\n",
    "    Создание директории для сохранения результатов\n",
    "    \"\"\"\n",
    "    output_dir = Path(base_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Создана директория для результатов: {output_dir.absolute()}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_piece_square_value(board, color):\n",
    "    \"\"\"\n",
    "    Расчет позиционной ценности фигур на основе piece-square tables\n",
    "    \"\"\"\n",
    "    pawn_table = [0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                  5, 5, 5, 5, 5, 5, 5, 5,\n",
    "                  1, 1, 2, 3, 3, 2, 1, 1,\n",
    "                  0, 0, 1, 2, 2, 1, 0, 0,\n",
    "                  0, 0, 0, 2, 2, 0, 0, 0,\n",
    "                  0, 0, 0, 1, 1, 0, 0, 0,\n",
    "                  0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                  0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    knight_table = [0, 1, 2, 2, 2, 2, 1, 0,\n",
    "                    1, 2, 3, 3, 3, 3, 2, 1,\n",
    "                    2, 3, 4, 4, 4, 4, 3, 2,\n",
    "                    2, 3, 4, 5, 5, 4, 3, 2,\n",
    "                    2, 3, 4, 5, 5, 4, 3, 2,\n",
    "                    2, 3, 4, 4, 4, 4, 3, 2,\n",
    "                    1, 2, 3, 3, 3, 3, 2, 1,\n",
    "                    0, 1, 2, 2, 2, 2, 1, 0]\n",
    "    \n",
    "    value = 0\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece and piece.color == color:\n",
    "            if piece.piece_type == chess.PAWN:\n",
    "                value += pawn_table[square if color == chess.WHITE else 63 - square]\n",
    "            elif piece.piece_type == chess.KNIGHT:\n",
    "                value += knight_table[square if color == chess.WHITE else 63 - square]\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_king_safety(board, color):\n",
    "    \"\"\"\n",
    "    Расчет безопасности короля\n",
    "    \"\"\"\n",
    "    king_square = board.king(color)\n",
    "    if king_square is None:\n",
    "        return -10  \n",
    "    \n",
    "    safety = 0\n",
    "    \n",
    "    if color == chess.WHITE:\n",
    "        pawn_shield_squares = [king_square + 8, king_square + 7, king_square + 9]\n",
    "    else:\n",
    "        pawn_shield_squares = [king_square - 8, king_square - 7, king_square - 9]\n",
    "    \n",
    "    for square in pawn_shield_squares:\n",
    "        if 0 <= square <= 63:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece and piece.piece_type == chess.PAWN and piece.color == color:\n",
    "                safety += 1\n",
    "    \n",
    "    king_file = chess.square_file(king_square)\n",
    "    for file_offset in [-1, 0, 1]:\n",
    "        file = king_file + file_offset\n",
    "        if 0 <= file <= 7:\n",
    "            has_pawn = False\n",
    "            for rank in range(8):\n",
    "                square = chess.square(file, rank)\n",
    "                piece = board.piece_at(square)\n",
    "                if piece and piece.piece_type == chess.PAWN and piece.color == color:\n",
    "                    has_pawn = True\n",
    "                    break\n",
    "            if not has_pawn:\n",
    "                safety -= 2\n",
    "    \n",
    "    return safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pawn_structure(board, color):\n",
    "    \"\"\"\n",
    "    Оценка пешечной структуры\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    pawns = board.pieces(chess.PAWN, color)\n",
    "\n",
    "    for pawn_square in pawns:\n",
    "        file = chess.square_file(pawn_square)\n",
    "        isolated = True\n",
    "        for adjacent_file in [file - 1, file + 1]:\n",
    "            if 0 <= adjacent_file <= 7:\n",
    "                for rank in range(8):\n",
    "                    square = chess.square(adjacent_file, rank)\n",
    "                    piece = board.piece_at(square)\n",
    "                    if piece and piece.piece_type == chess.PAWN and piece.color == color:\n",
    "                        isolated = False\n",
    "                        break\n",
    "                if not isolated:\n",
    "                    break\n",
    "        if isolated:\n",
    "            score -= 1\n",
    "    \n",
    "    file_counts = [0] * 8\n",
    "    for pawn_square in pawns:\n",
    "        file = chess.square_file(pawn_square)\n",
    "        file_counts[file] += 1\n",
    "    \n",
    "    for count in file_counts:\n",
    "        if count > 1:\n",
    "            score -= (count - 1)\n",
    "    \n",
    "    for pawn_square in pawns:\n",
    "        file = chess.square_file(pawn_square)\n",
    "        rank = chess.square_rank(pawn_square)\n",
    "        \n",
    "        is_passed = True\n",
    "        if color == chess.WHITE:\n",
    "            for check_rank in range(rank + 1, 8):\n",
    "                for check_file in [file - 1, file, file + 1]:\n",
    "                    if 0 <= check_file <= 7:\n",
    "                        square = chess.square(check_file, check_rank)\n",
    "                        piece = board.piece_at(square)\n",
    "                        if piece and piece.piece_type == chess.PAWN and piece.color != color:\n",
    "                            is_passed = False\n",
    "                            break\n",
    "                if not is_passed:\n",
    "                    break\n",
    "        else:\n",
    "            for check_rank in range(rank - 1, -1, -1):\n",
    "                for check_file in [file - 1, file, file + 1]:\n",
    "                    if 0 <= check_file <= 7:\n",
    "                        square = chess.square(check_file, check_rank)\n",
    "                        piece = board.piece_at(square)\n",
    "                        if piece and piece.piece_type == chess.PAWN and piece.color != color:\n",
    "                            is_passed = False\n",
    "                            break\n",
    "                if not is_passed:\n",
    "                    break\n",
    "        \n",
    "        if is_passed:\n",
    "            score += 2\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_move_features(game, move_number):\n",
    "    \"\"\"\n",
    "    Извлечение улучшенных признаков для конкретного хода\n",
    "    \"\"\"\n",
    "    board = chess.Board()\n",
    "    features = []\n",
    "    \n",
    "    for i, move in enumerate(game.mainline_moves()):\n",
    "        if i >= move_number:\n",
    "            break\n",
    "        board.push(move)\n",
    "    \n",
    "    pawn_diff = len(board.pieces(chess.PAWN, chess.WHITE)) - len(board.pieces(chess.PAWN, chess.BLACK))\n",
    "    knight_diff = len(board.pieces(chess.KNIGHT, chess.WHITE)) - len(board.pieces(chess.KNIGHT, chess.BLACK))\n",
    "    bishop_diff = len(board.pieces(chess.BISHOP, chess.WHITE)) - len(board.pieces(chess.BISHOP, chess.BLACK))\n",
    "    rook_diff = len(board.pieces(chess.ROOK, chess.WHITE)) - len(board.pieces(chess.ROOK, chess.BLACK))\n",
    "    queen_diff = len(board.pieces(chess.QUEEN, chess.WHITE)) - len(board.pieces(chess.QUEEN, chess.BLACK))\n",
    "    \n",
    "    material_value = pawn_diff * 1 + knight_diff * 3 + bishop_diff * 3 + rook_diff * 5 + queen_diff * 9\n",
    "    \n",
    "    center_squares = [chess.E4, chess.E5, chess.D4, chess.D5]\n",
    "    extended_center = [chess.C3, chess.C4, chess.C5, chess.C6, chess.D3, chess.D6, \n",
    "                      chess.E3, chess.E6, chess.F3, chess.F4, chess.F5, chess.F6]\n",
    "    \n",
    "    center_control = 0\n",
    "    extended_center_control = 0\n",
    "    \n",
    "    for square in center_squares:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            if piece.color == chess.WHITE:\n",
    "                center_control += 2\n",
    "            else:\n",
    "                center_control -= 2\n",
    "        if board.is_attacked_by(chess.WHITE, square):\n",
    "            center_control += 1\n",
    "        if board.is_attacked_by(chess.BLACK, square):\n",
    "            center_control -= 1\n",
    "    \n",
    "    for square in extended_center:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece:\n",
    "            if piece.color == chess.WHITE:\n",
    "                extended_center_control += 1\n",
    "            else:\n",
    "                extended_center_control -= 1\n",
    "    \n",
    "    white_mobility = len(list(board.legal_moves)) if board.turn == chess.WHITE else 0\n",
    "    board.turn = not board.turn\n",
    "    black_mobility = len(list(board.legal_moves)) if board.turn == chess.BLACK else 0\n",
    "    board.turn = not board.turn\n",
    "    mobility_diff = white_mobility - black_mobility\n",
    "    \n",
    "    white_king_safety = calculate_king_safety(board, chess.WHITE)\n",
    "    black_king_safety = calculate_king_safety(board, chess.BLACK)\n",
    "    king_safety_diff = white_king_safety - black_king_safety\n",
    "    \n",
    "    white_development = 0\n",
    "    black_development = 0\n",
    "    \n",
    "    for piece_type in [chess.KNIGHT, chess.BISHOP]:\n",
    "        for square in board.pieces(piece_type, chess.WHITE):\n",
    "            if chess.square_rank(square) > 1:  \n",
    "                white_development += 1\n",
    "                if square in center_squares or square in extended_center:\n",
    "                    white_development += 0.5  \n",
    "        \n",
    "        for square in board.pieces(piece_type, chess.BLACK):\n",
    "            if chess.square_rank(square) < 6:  \n",
    "                black_development += 1\n",
    "                if square in center_squares or square in extended_center:\n",
    "                    black_development += 0.5\n",
    "    \n",
    "    development_diff = white_development - black_development\n",
    "    \n",
    "    white_pawn_structure = calculate_pawn_structure(board, chess.WHITE)\n",
    "    black_pawn_structure = calculate_pawn_structure(board, chess.BLACK)\n",
    "    pawn_structure_diff = white_pawn_structure - black_pawn_structure\n",
    "    \n",
    "    white_piece_square = calculate_piece_square_value(board, chess.WHITE)\n",
    "    black_piece_square = calculate_piece_square_value(board, chess.BLACK)\n",
    "    piece_square_diff = white_piece_square - black_piece_square\n",
    "    \n",
    "    important_squares = [chess.E4, chess.E5, chess.D4, chess.D5, chess.F7, chess.F2]\n",
    "    square_control = 0\n",
    "    for square in important_squares:\n",
    "        if board.is_attacked_by(chess.WHITE, square):\n",
    "            square_control += 1\n",
    "        if board.is_attacked_by(chess.BLACK, square):\n",
    "            square_control -= 1\n",
    "    \n",
    "    total_pieces = len(board.piece_map())\n",
    "    game_phase = min(total_pieces / 32.0, 1.0)  \n",
    "    \n",
    "    tempo = move_number / 40.0  \n",
    "    \n",
    "    features.extend([\n",
    "        pawn_diff, knight_diff, bishop_diff, rook_diff, queen_diff,  \n",
    "        material_value,  \n",
    "        center_control, extended_center_control,  \n",
    "        mobility_diff,  \n",
    "        king_safety_diff,  \n",
    "        development_diff,  \n",
    "        pawn_structure_diff,  \n",
    "        piece_square_diff,  \n",
    "        square_control,  \n",
    "        game_phase,  \n",
    "        tempo,  \n",
    "        white_mobility, black_mobility,  \n",
    "        white_king_safety, black_king_safety,  \n",
    "        white_development, black_development,  \n",
    "        white_pawn_structure, black_pawn_structure,  \n",
    "        white_piece_square, black_piece_square  \n",
    "    ])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_chess_database(file_path, max_games=100):\n",
    "    \"\"\"\n",
    "    Предобработка базы данных шахматных партий с фильтрацией качественных игр\n",
    "    \"\"\"\n",
    "    print(\"Начало предобработки данных...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    game_metadata = []\n",
    "    \n",
    "    result_counts = {1: 0, -1: 0, 0: 0}  \n",
    "    max_white_wins = int(max_games * 0.33) \n",
    "    max_black_wins = int(max_games * 0.33)  \n",
    "    max_draws = int(max_games * 0.33)      \n",
    "    \n",
    "    max_per_result = {1: max_white_wins, -1: max_black_wins, 0: max_draws}\n",
    "    \n",
    "    with open(file_path, 'rb') as fh:\n",
    "        dctx = zstd.ZstdDecompressor()\n",
    "        with dctx.stream_reader(fh) as reader:\n",
    "            text_reader = io.TextIOWrapper(reader, encoding='utf-8')\n",
    "            pgn = chess.pgn.read_game(text_reader)\n",
    "            game_count = 0\n",
    "            processed_games = 0\n",
    "            \n",
    "            while pgn and (result_counts[1] < max_white_wins or result_counts[-1] < max_black_wins or result_counts[0] < max_draws):\n",
    "                result = pgn.headers.get('Result', '*')\n",
    "                if result == '1-0':\n",
    "                    result_value = 1  \n",
    "                elif result == '0-1':\n",
    "                    result_value = -1  \n",
    "                elif result == '1/2-1/2':\n",
    "                    result_value = 0  \n",
    "                else:\n",
    "                    pgn = chess.pgn.read_game(text_reader)\n",
    "                    continue  \n",
    "                \n",
    "                white_elo = pgn.headers.get('WhiteElo', '0')\n",
    "                black_elo = pgn.headers.get('BlackElo', '0')\n",
    "                time_control = pgn.headers.get('TimeControl', '')\n",
    "                \n",
    "                try:\n",
    "                    white_elo = int(white_elo) if white_elo.isdigit() else 0\n",
    "                    black_elo = int(black_elo) if black_elo.isdigit() else 0\n",
    "                except:\n",
    "                    white_elo = black_elo = 0\n",
    "\n",
    "                if white_elo < 1200 or black_elo < 1200:\n",
    "                    pgn = chess.pgn.read_game(text_reader)\n",
    "                    continue\n",
    "                \n",
    "                if abs(white_elo - black_elo) > 400:\n",
    "                    pgn = chess.pgn.read_game(text_reader)\n",
    "                    continue\n",
    "                \n",
    "                if 'bullet' in time_control.lower() or ('60+' in time_control and '0' in time_control):\n",
    "                    pgn = chess.pgn.read_game(text_reader)\n",
    "                    continue\n",
    "                \n",
    "                if result_counts[result_value] >= max_per_result[result_value]:\n",
    "                    pgn = chess.pgn.read_game(text_reader)\n",
    "                    continue\n",
    "                \n",
    "                move_list = list(pgn.mainline_moves())\n",
    "                if len(move_list) < 10 or len(move_list) > 100:  \n",
    "                    pgn = chess.pgn.read_game(text_reader)\n",
    "                    continue\n",
    "                \n",
    "                total_moves = len(move_list)\n",
    "                \n",
    "                move_indices = []\n",
    "                \n",
    "                for i in range(5, min(15, total_moves), 2):\n",
    "                    move_indices.append(i)\n",
    "                \n",
    "                if total_moves > 15:\n",
    "                    for i in range(15, min(40, total_moves), 3):\n",
    "                        move_indices.append(i)\n",
    "                \n",
    "                if total_moves > 40:\n",
    "                    for i in range(max(40, total_moves - 15), total_moves, 2):\n",
    "                        move_indices.append(i)\n",
    "                \n",
    "                move_indices = move_indices[:15]\n",
    "                \n",
    "                for move_idx in move_indices:\n",
    "                    if move_idx < total_moves:\n",
    "                        features = extract_move_features(pgn, move_idx)\n",
    "                        features_list.append(features)\n",
    "                        labels_list.append(result_value)\n",
    "                        game_metadata.append({\n",
    "                            'game_id': processed_games,\n",
    "                            'move_number': move_idx,\n",
    "                            'white_elo': white_elo,\n",
    "                            'black_elo': black_elo,\n",
    "                            'game_phase': 'opening' if move_idx < 15 else ('middlegame' if move_idx < 40 else 'endgame')\n",
    "                        })\n",
    "                \n",
    "                result_counts[result_value] += 1\n",
    "                processed_games += 1\n",
    "                \n",
    "                if processed_games % 100 == 0:\n",
    "                    print(f\"Обработано {processed_games} игр. Распределение: Белые: {result_counts[1]}, Черные: {result_counts[-1]}, Ничьи: {result_counts[0]}\")\n",
    "                \n",
    "                pgn = chess.pgn.read_game(text_reader)\n",
    "    \n",
    "    df = pd.DataFrame(features_list, columns=[\n",
    "        'pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff',  \n",
    "        'material_value',  \n",
    "        'center_control', 'extended_center_control',  \n",
    "        'mobility_diff',  \n",
    "        'king_safety_diff',  \n",
    "        'development_diff',  \n",
    "        'pawn_structure_diff',  \n",
    "        'piece_square_diff',  \n",
    "        'square_control',  \n",
    "        'game_phase',  \n",
    "        'tempo',  \n",
    "        'white_mobility', 'black_mobility',  \n",
    "        'white_king_safety', 'black_king_safety',  \n",
    "        'white_development', 'black_development',  \n",
    "        'white_pawn_structure', 'black_pawn_structure',  \n",
    "        'white_piece_square', 'black_piece_square'  \n",
    "    ])\n",
    "    df['result'] = labels_list\n",
    "    \n",
    "    print(f\"\\nПредобработка завершена за {time.time() - start_time:.2f} секунд\")\n",
    "    print(f\"Обработано {processed_games} игр\")\n",
    "    print(f\"Получено {len(df)} позиций\")\n",
    "    print(f\"Финальное распределение результатов:\")\n",
    "    print(f\"  Победы белых: {result_counts[1]} игр\")\n",
    "    print(f\"  Победы черных: {result_counts[-1]} игр\") \n",
    "    print(f\"  Ничьи: {result_counts[0]} игр\")\n",
    "    \n",
    "    metadata_df = pd.DataFrame(game_metadata)\n",
    "    df = pd.concat([df, metadata_df], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    output_dir = create_output_directory()\n",
    "    \n",
    "    db_file = \"lichess_db_standard_rated_2013-01.pgn.zst\"\n",
    "    if not Path(db_file).exists():\n",
    "        download_chess_database()\n",
    "    \n",
    "    df = preprocess_chess_database(db_file)\n",
    "\n",
    "    output_file = output_dir / \"processed_chess_data.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nДанные сохранены в {output_file}\")\n",
    "    \n",
    "    report_file = output_dir / \"data_report.txt\"\n",
    "    with open(report_file, 'w') as f:\n",
    "        f.write(\"Отчет о предобработке данных\\n\")\n",
    "        f.write(\"==========================\\n\\n\")\n",
    "        f.write(f\"Количество позиций: {len(df)}\\n\")\n",
    "        f.write(f\"Количество признаков: {len(df.columns) - 1}\\n\")\n",
    "        f.write(\"\\nСтатистика по результатам:\\n\")\n",
    "        f.write(df['result'].value_counts().to_string())\n",
    "        f.write(\"\\n\\nСтатистика по признакам:\\n\")\n",
    "        f.write(df.describe().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создана директория для результатов: /Users/skolkoff/Desktop/StoneS_ЭП/preprocessed_data\n",
      "Начало предобработки данных...\n",
      "\n",
      "Предобработка завершена за 3.34 секунд\n",
      "Обработано 99 игр\n",
      "Получено 1358 позиций\n",
      "Финальное распределение результатов:\n",
      "  Победы белых: 33 игр\n",
      "  Победы черных: 33 игр\n",
      "  Ничьи: 33 игр\n",
      "\n",
      "Данные сохранены в preprocessed_data/processed_chess_data.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(base_path=\"exploratory_analysis_results\"):\n",
    "    \"\"\"\n",
    "    Создание директории для сохранения результатов анализа\n",
    "    \"\"\"\n",
    "    output_dir = Path(base_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Создана директория для результатов: {output_dir.absolute()}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Загрузка предобработанных данных\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('preprocessed_data/processed_chess_data.csv')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_distributions(df, output_dir):\n",
    "    \"\"\"\n",
    "    Анализ распределений признаков\n",
    "    \"\"\"\n",
    "    print(\"\\nАнализ распределений признаков...\")\n",
    "    \n",
    "    features = ['pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff',\n",
    "                'material_value', 'center_control', 'extended_center_control', 'mobility_diff',\n",
    "                'king_safety_diff', 'development_diff', 'pawn_structure_diff', 'piece_square_diff',\n",
    "                'square_control', 'game_phase', 'tempo']\n",
    "    \n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "    if len(available_features) != len(features):\n",
    "        print(f\"Внимание: Доступно только {len(available_features)} из {len(features)} признаков\")\n",
    "        features = available_features\n",
    "    \n",
    "    numeric_features = []\n",
    "    categorical_features = []\n",
    "    \n",
    "    for feature in features:\n",
    "        if df[feature].dtype in ['object', 'string']:\n",
    "            categorical_features.append(feature)\n",
    "        else:\n",
    "            numeric_features.append(feature)\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=df, x=feature, bins=30)\n",
    "        plt.title(f'Распределение признака {feature}')\n",
    "        plt.savefig(output_dir / f'{feature}_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        df[feature].value_counts().plot(kind='bar')\n",
    "        plt.title(f'Распределение признака {feature}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / f'{feature}_distribution.png')\n",
    "        plt.close()\n",
    "    \n",
    "    if numeric_features:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        correlation_matrix = df[numeric_features].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "        plt.title('Корреляционная матрица числовых признаков')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'correlation_matrix.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_move_patterns(df, output_dir):\n",
    "    \"\"\"\n",
    "    Анализ паттернов ходов\n",
    "    \"\"\"\n",
    "    print(\"\\nАнализ паттернов ходов...\")\n",
    "    \n",
    "    if 'material_value' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='result', y='material_value')\n",
    "        plt.title('Распределение материального преимущества по результатам')\n",
    "        plt.savefig(output_dir / 'material_advantage_by_result.png')\n",
    "        plt.close()\n",
    "    \n",
    "    if 'center_control' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='result', y='center_control')\n",
    "        plt.title('Распределение контроля центра по результатам')\n",
    "        plt.savefig(output_dir / 'center_control_by_result.png')\n",
    "        plt.close()\n",
    "    \n",
    "    if 'mobility_diff' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='result', y='mobility_diff')\n",
    "        plt.title('Распределение разности мобильности по результатам')\n",
    "        plt.savefig(output_dir / 'mobility_diff_by_result.png')\n",
    "        plt.close()\n",
    "    \n",
    "    if 'king_safety_diff' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='result', y='king_safety_diff')\n",
    "        plt.title('Распределение безопасности короля по результатам')\n",
    "        plt.savefig(output_dir / 'king_safety_by_result.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca_analysis(df, output_dir):\n",
    "    \"\"\"\n",
    "    Анализ главных компонент\n",
    "    \"\"\"\n",
    "    print(\"\\nВыполнение PCA анализа...\")\n",
    "    \n",
    "    features = ['pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff',\n",
    "                'material_value', 'center_control', 'extended_center_control', 'mobility_diff',\n",
    "                'king_safety_diff', 'development_diff', 'pawn_structure_diff', 'piece_square_diff',\n",
    "                'square_control', 'game_phase', 'tempo']\n",
    "    \n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "    if len(available_features) != len(features):\n",
    "        print(f\"Внимание: Доступно только {len(available_features)} из {len(features)} признаков\")\n",
    "        features = available_features\n",
    "    \n",
    "    numeric_features = []\n",
    "    for feature in features:\n",
    "        if df[feature].dtype in ['int64', 'float64']:\n",
    "            numeric_features.append(feature)\n",
    "    \n",
    "    if not numeric_features:\n",
    "        print(\"Нет числовых признаков для PCA анализа\")\n",
    "        return None\n",
    "    \n",
    "    X = df[numeric_features]\n",
    "    features = numeric_features  \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('Количество компонент')\n",
    "    plt.ylabel('Объясненная дисперсия')\n",
    "    plt.title('Кумулятивная объясненная дисперсия')\n",
    "    plt.savefig(output_dir / 'pca_explained_variance.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['result'], cmap='viridis')\n",
    "    plt.colorbar(scatter, label='Результат')\n",
    "    plt.xlabel('Первая главная компонента')\n",
    "    plt.ylabel('Вторая главная компонента')\n",
    "    plt.title('PCA: первые две компоненты')\n",
    "    plt.savefig(output_dir / 'pca_first_two_components.png')\n",
    "    plt.close()\n",
    "    \n",
    "    component_info = pd.DataFrame(\n",
    "        pca.components_,\n",
    "        columns=features,\n",
    "        index=[f'PC{i+1}' for i in range(len(features))]\n",
    "    )\n",
    "    component_info.to_csv(output_dir / 'pca_components.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_report(df, output_dir):\n",
    "    \"\"\"\n",
    "    Генерация отчета по анализу\n",
    "    \"\"\"\n",
    "    print(\"\\nГенерация отчета...\")\n",
    "    \n",
    "    with open(output_dir / 'analysis_report.txt', 'w') as f:\n",
    "        f.write(\"Отчет по исследовательскому анализу данных\\n\")\n",
    "        f.write(\"=======================================\\n\\n\")\n",
    "        \n",
    "        f.write(\"1. Общая информация о данных:\\n\")\n",
    "        f.write(f\"Количество позиций: {len(df)}\\n\")\n",
    "        f.write(f\"Количество признаков: {len(df.columns) - 1}\\n\\n\")\n",
    "        \n",
    "        f.write(\"2. Статистика по результатам:\\n\")\n",
    "        f.write(df['result'].value_counts().to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"3. Описательная статистика признаков:\\n\")\n",
    "        f.write(df.describe().to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"4. Корреляции между признаками:\\n\")\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        exclude_columns = ['result', 'game_id', 'move_number', 'white_elo', 'black_elo']\n",
    "        numeric_features = [col for col in numeric_columns if col not in exclude_columns]\n",
    "        \n",
    "        if numeric_features:\n",
    "            f.write(df[numeric_features].corr().to_string())\n",
    "        else:\n",
    "            f.write(\"Числовые признаки не найдены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    output_dir = create_output_directory()\n",
    "    df = load_data()\n",
    "    analyze_feature_distributions(df, output_dir)\n",
    "    analyze_move_patterns(df, output_dir)\n",
    "    perform_pca_analysis(df, output_dir)\n",
    "    generate_analysis_report(df, output_dir)\n",
    "    \n",
    "    print(f\"\\nАнализ завершен. Результаты сохранены в {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создана директория для результатов: /Users/skolkoff/Desktop/StoneS_ЭП/exploratory_analysis_results\n",
      "\n",
      "Анализ распределений признаков...\n",
      "\n",
      "Анализ паттернов ходов...\n",
      "\n",
      "Выполнение PCA анализа...\n",
      "\n",
      "Генерация отчета...\n",
      "\n",
      "Анализ завершен. Результаты сохранены в exploratory_analysis_results\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(base_path=\"model_figures\"):\n",
    "    \"\"\"\n",
    "    Создание директории для сохранения графиков\n",
    "    \"\"\"\n",
    "    output_dir = Path(base_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Создана директория для графиков: {output_dir.absolute()}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    \"\"\"\n",
    "    Загрузка и подготовка данных для обучения\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('preprocessed_data/processed_chess_data.csv')\n",
    "        print(f\"Загружено {len(df)} строк данных\")\n",
    "        \n",
    "        features = ['pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff',\n",
    "                   'material_value', 'center_control', 'extended_center_control', 'mobility_diff',\n",
    "                   'king_safety_diff', 'development_diff', 'pawn_structure_diff', 'piece_square_diff',\n",
    "                   'square_control', 'game_phase', 'tempo', 'white_mobility', 'black_mobility',\n",
    "                   'white_king_safety', 'black_king_safety', 'white_development', 'black_development',\n",
    "                   'white_pawn_structure', 'black_pawn_structure', 'white_piece_square', 'black_piece_square']\n",
    "        \n",
    "        available_features = [f for f in features if f in df.columns]\n",
    "        if len(available_features) != len(features):\n",
    "            print(f\"Внимание: Доступно только {len(available_features)} из {len(features)} признаков\")\n",
    "            print(f\"Недостающие признаки: {set(features) - set(available_features)}\")\n",
    "        \n",
    "        X = df[available_features]\n",
    "        \n",
    "        y = df['result'].map({-1: 0, 0: 1, 1: 2})\n",
    "        \n",
    "        print(f\"Размерность признаков: {X.shape}\")\n",
    "        print(f\"Размерность целевой переменной: {y.shape}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "        print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_robust_cross_validation(model, X, y, cv_strategies):\n",
    "    \"\"\"\n",
    "    Выполнение кросс-валидации с использованием различных стратегий\n",
    "    \"\"\"\n",
    "    cv_results = {}\n",
    "    \n",
    "    for name, cv in cv_strategies.items():\n",
    "        try:\n",
    "            scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "            cv_results[name] = {\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "                'scores': scores\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при выполнении {name} кросс-валидации: {str(e)}\")\n",
    "            cv_results[name] = {\n",
    "                'mean_score': 0,\n",
    "                'std_score': 0,\n",
    "                'scores': []\n",
    "            }\n",
    "    \n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(X_train, X_test, y_train, y_test, output_dir):\n",
    "    \"\"\"\n",
    "    Обучение и оценка различных моделей с балансировкой классов\n",
    "    \"\"\"\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "    class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "    \n",
    "    print(f\"Веса классов для балансировки: {class_weight_dict}\")\n",
    "    \n",
    "    models = {\n",
    "        'Логистическая регрессия': LogisticRegression(\n",
    "            max_iter=2000, random_state=42, class_weight='balanced',\n",
    "            C=0.1, solver='liblinear'\n",
    "        ),\n",
    "        'Дерево решений': DecisionTreeClassifier(\n",
    "            random_state=42, class_weight='balanced',\n",
    "            max_depth=10, min_samples_split=20, min_samples_leaf=10\n",
    "        ),\n",
    "        'Случайный лес': RandomForestClassifier(\n",
    "            n_estimators=200, random_state=42, class_weight='balanced',\n",
    "            max_depth=15, min_samples_split=10, min_samples_leaf=5,\n",
    "            max_features='sqrt'\n",
    "        ),\n",
    "        'Градиентный бустинг': GradientBoostingClassifier(\n",
    "            n_estimators=200, random_state=42, learning_rate=0.1,\n",
    "            max_depth=6, min_samples_split=20, min_samples_leaf=10\n",
    "        ),\n",
    "        'AdaBoost': AdaBoostClassifier(\n",
    "            n_estimators=100, algorithm='SAMME', random_state=42,\n",
    "            learning_rate=0.8\n",
    "        ),\n",
    "        'SVM': SVC(\n",
    "            random_state=42, class_weight='balanced',\n",
    "            C=1.0, kernel='rbf', gamma='scale'\n",
    "        ),\n",
    "        'Нейронная сеть': MLPClassifier(\n",
    "            hidden_layer_sizes=(200, 100, 50), max_iter=2000, random_state=42,\n",
    "            alpha=0.01, learning_rate='adaptive', early_stopping=True,\n",
    "            validation_fraction=0.1\n",
    "        ),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "    }\n",
    "    \n",
    "    cv_strategies = {\n",
    "        'KFold': KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        'StratifiedKFold': StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            print(f\"\\nОбучение модели: {name}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            train_time = time.time() - start_time\n",
    "            \n",
    "            cv_results = perform_robust_cross_validation(model, X_train, y_train, cv_strategies)\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            \n",
    "            metrics = {\n",
    "                'Модель': name,\n",
    "                'Время обучения (с)': train_time,\n",
    "                'Точность (accuracy)': accuracy_score(y_test, y_pred),\n",
    "                'Precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "                'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
    "                'F1-score': f1_score(y_test, y_pred, average='weighted'),\n",
    "                'KFold CV Score': cv_results['KFold']['mean_score'],\n",
    "                'KFold CV Std': cv_results['KFold']['std_score'],\n",
    "                'StratifiedKFold CV Score': cv_results['StratifiedKFold']['mean_score'],\n",
    "                'StratifiedKFold CV Std': cv_results['StratifiedKFold']['std_score']\n",
    "            }\n",
    "            \n",
    "            results.append(metrics)\n",
    "            \n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Матрица ошибок - {name}')\n",
    "            plt.xlabel('Предсказанный класс')\n",
    "            plt.ylabel('Истинный класс')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / f'confusion_matrix_{name.lower().replace(\" \", \"_\")}.png')\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Время обучения: {train_time:.2f} секунд\")\n",
    "            print(f\"Точность на тестовой выборке: {metrics['Точность (accuracy)']:.4f}\")\n",
    "            print(f\"KFold CV Score: {metrics['KFold CV Score']:.4f} ± {metrics['KFold CV Std']:.4f}\")\n",
    "            print(f\"StratifiedKFold CV Score: {metrics['StratifiedKFold CV Score']:.4f} ± {metrics['StratifiedKFold CV Std']:.4f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred, zero_division=0))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обучении модели {name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(results_df, output_dir):\n",
    "    \"\"\"\n",
    "    Визуализация результатов обучения моделей\n",
    "    \"\"\"\n",
    "    try:\n",
    "        metrics = ['Точность (accuracy)', 'Precision', 'Recall', 'F1-score']\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        results_df.plot(x='Модель', y=metrics, kind='bar')\n",
    "        plt.title('Сравнение метрик для разных моделей')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir /'model_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.barplot(data=results_df, x='Модель', y='Время обучения (с)')\n",
    "        plt.title('Время обучения моделей')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir /'training_time_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        results_df.plot(x='Модель', y=['KFold CV Score', 'StratifiedKFold CV Score'], kind='bar')\n",
    "        plt.title('Сравнение результатов кросс-валидации')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / 'cv_accuracy_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"\\nСводная таблица результатов:\")\n",
    "        print(results_df.to_string(float_format='{:.4f}'.format))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при визуализации результатов: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessMoveDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels.values if hasattr(labels, 'values') else labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessMoveNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.2):\n",
    "        super(ChessMoveNetwork, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                num_epochs, device, output_dir):\n",
    "    print(\"\\nНачало обучения модели...\")\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    best_val_accuracy = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), output_dir / 'best_model.pth')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_loss:.4f}, '\n",
    "              f'Train Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, '\n",
    "              f'Val Accuracy: {val_accuracy:.2f}%')\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(train_losses, val_losses, train_accuracies, \n",
    "                             val_accuracies, output_dir):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(output_dir / 'loss_plot.png')\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(output_dir / 'accuracy_plot.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, output_dir):\n",
    "    print(\"\\nОценка модели на тестовой выборке...\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features = features.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(\n",
    "        pd.Series(all_labels, name='Actual'),\n",
    "        pd.Series(all_predictions, name='Predicted')\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(output_dir / 'confusion_matrix.png')\n",
    "    plt.close()\n",
    "    \n",
    "    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    output_dir = create_output_directory(\"model_training_results\")\n",
    "    X_train, X_test, y_train, y_test = load_and_prepare_data()\n",
    "    input_size = X_train.shape[1]  \n",
    "    hidden_sizes = [256, 128, 64]  \n",
    "    output_size = 3  \n",
    "    batch_size = 64\n",
    "    num_epochs = 50\n",
    "    learning_rate = 0.001\n",
    "    dropout_rate = 0.2\n",
    "    \n",
    "    print(f\"Размер входного слоя: {input_size}\")\n",
    "    print(f\"Архитектура сети: {input_size} -> {' -> '.join(map(str, hidden_sizes))} -> {output_size}\")\n",
    "    \n",
    "    train_dataset = ChessMoveDataset(X_train, y_train)\n",
    "    test_dataset = ChessMoveDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Используется устройство: {device}\")\n",
    "    model = ChessMoveNetwork(input_size, hidden_sizes, output_size, dropout_rate)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    start_time = time.time()\n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
    "        model, train_loader, test_loader, criterion, optimizer, \n",
    "        num_epochs, device, output_dir\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    visualize_training_results(\n",
    "        train_losses, val_losses, train_accuracies, val_accuracies, output_dir\n",
    "    )\n",
    "    test_accuracy = evaluate_model(model, test_loader, device, output_dir)\n",
    "    with open(output_dir / 'model_info.txt', 'w') as f:\n",
    "        f.write(\"Информация о модели\\n\")\n",
    "        f.write(\"==================\\n\\n\")\n",
    "        f.write(f\"Архитектура:\\n\")\n",
    "        f.write(f\"- Входной слой: {input_size} нейронов\\n\")\n",
    "        f.write(f\"- Скрытые слои: {hidden_sizes}\\n\")\n",
    "        f.write(f\"- Выходной слой: {output_size} нейронов\\n\")\n",
    "        f.write(f\"- Dropout rate: {dropout_rate}\\n\\n\")\n",
    "        f.write(f\"Параметры обучения:\\n\")\n",
    "        f.write(f\"- Batch size: {batch_size}\\n\")\n",
    "        f.write(f\"- Количество эпох: {num_epochs}\\n\")\n",
    "        f.write(f\"- Learning rate: {learning_rate}\\n\")\n",
    "        f.write(f\"- Оптимизатор: Adam\\n\")\n",
    "        f.write(f\"- Функция потерь: CrossEntropyLoss\\n\\n\")\n",
    "        f.write(f\"Результаты:\\n\")\n",
    "        f.write(f\"- Время обучения: {training_time:.2f} секунд\\n\")\n",
    "        f.write(f\"- Точность на тестовой выборке: {test_accuracy:.4f}\\n\")\n",
    "    \n",
    "    print(f\"\\nОбучение завершено за {training_time:.2f} секунд\")\n",
    "    print(f\"Результаты сохранены в {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создана директория для графиков: /Users/skolkoff/Desktop/StoneS_ЭП/model_training_results\n",
      "Загружено 1358 строк данных\n",
      "Размерность признаков: (1358, 26)\n",
      "Размерность целевой переменной: (1358,)\n",
      "Размер обучающей выборки: (1086, 26)\n",
      "Размер тестовой выборки: (272, 26)\n",
      "Размер входного слоя: 26\n",
      "Архитектура сети: 26 -> 256 -> 128 -> 64 -> 3\n",
      "Используется устройство: cpu\n",
      "\n",
      "Начало обучения модели...\n",
      "Epoch [1/50], Train Loss: 1.1155, Train Accuracy: 41.44%, Val Loss: 1.0068, Val Accuracy: 50.37%\n",
      "Epoch [2/50], Train Loss: 0.9861, Train Accuracy: 50.00%, Val Loss: 0.9350, Val Accuracy: 54.78%\n",
      "Epoch [3/50], Train Loss: 0.9341, Train Accuracy: 56.35%, Val Loss: 0.8756, Val Accuracy: 59.93%\n",
      "Epoch [4/50], Train Loss: 0.8993, Train Accuracy: 58.93%, Val Loss: 0.8388, Val Accuracy: 62.87%\n",
      "Epoch [5/50], Train Loss: 0.8543, Train Accuracy: 58.56%, Val Loss: 0.8017, Val Accuracy: 62.87%\n",
      "Epoch [6/50], Train Loss: 0.8258, Train Accuracy: 60.68%, Val Loss: 0.8015, Val Accuracy: 64.34%\n",
      "Epoch [7/50], Train Loss: 0.7876, Train Accuracy: 64.00%, Val Loss: 0.7830, Val Accuracy: 63.97%\n",
      "Epoch [8/50], Train Loss: 0.7595, Train Accuracy: 65.75%, Val Loss: 0.7691, Val Accuracy: 63.24%\n",
      "Epoch [9/50], Train Loss: 0.7713, Train Accuracy: 64.00%, Val Loss: 0.7400, Val Accuracy: 65.44%\n",
      "Epoch [10/50], Train Loss: 0.7257, Train Accuracy: 67.40%, Val Loss: 0.7399, Val Accuracy: 67.28%\n",
      "Epoch [11/50], Train Loss: 0.7034, Train Accuracy: 67.59%, Val Loss: 0.7196, Val Accuracy: 66.91%\n",
      "Epoch [12/50], Train Loss: 0.6651, Train Accuracy: 71.82%, Val Loss: 0.7171, Val Accuracy: 67.28%\n",
      "Epoch [13/50], Train Loss: 0.6569, Train Accuracy: 71.64%, Val Loss: 0.6900, Val Accuracy: 69.12%\n",
      "Epoch [14/50], Train Loss: 0.6361, Train Accuracy: 71.92%, Val Loss: 0.7057, Val Accuracy: 69.49%\n",
      "Epoch [15/50], Train Loss: 0.6344, Train Accuracy: 72.84%, Val Loss: 0.7135, Val Accuracy: 69.12%\n",
      "Epoch [16/50], Train Loss: 0.6328, Train Accuracy: 72.93%, Val Loss: 0.7091, Val Accuracy: 66.91%\n",
      "Epoch [17/50], Train Loss: 0.5472, Train Accuracy: 77.35%, Val Loss: 0.6864, Val Accuracy: 69.85%\n",
      "Epoch [18/50], Train Loss: 0.5794, Train Accuracy: 74.31%, Val Loss: 0.7097, Val Accuracy: 69.49%\n",
      "Epoch [19/50], Train Loss: 0.5597, Train Accuracy: 75.69%, Val Loss: 0.7058, Val Accuracy: 66.91%\n",
      "Epoch [20/50], Train Loss: 0.5297, Train Accuracy: 78.91%, Val Loss: 0.7074, Val Accuracy: 66.54%\n",
      "Epoch [21/50], Train Loss: 0.5099, Train Accuracy: 77.53%, Val Loss: 0.6953, Val Accuracy: 66.91%\n",
      "Epoch [22/50], Train Loss: 0.4941, Train Accuracy: 79.83%, Val Loss: 0.6867, Val Accuracy: 66.91%\n",
      "Epoch [23/50], Train Loss: 0.5162, Train Accuracy: 77.62%, Val Loss: 0.6673, Val Accuracy: 70.59%\n",
      "Epoch [24/50], Train Loss: 0.4969, Train Accuracy: 79.01%, Val Loss: 0.7273, Val Accuracy: 69.49%\n",
      "Epoch [25/50], Train Loss: 0.4633, Train Accuracy: 81.31%, Val Loss: 0.6535, Val Accuracy: 70.59%\n",
      "Epoch [26/50], Train Loss: 0.4517, Train Accuracy: 80.94%, Val Loss: 0.6520, Val Accuracy: 70.22%\n",
      "Epoch [27/50], Train Loss: 0.4637, Train Accuracy: 80.29%, Val Loss: 0.6949, Val Accuracy: 70.22%\n",
      "Epoch [28/50], Train Loss: 0.4512, Train Accuracy: 80.85%, Val Loss: 0.6783, Val Accuracy: 71.69%\n",
      "Epoch [29/50], Train Loss: 0.4186, Train Accuracy: 83.06%, Val Loss: 0.6895, Val Accuracy: 72.06%\n",
      "Epoch [30/50], Train Loss: 0.4550, Train Accuracy: 80.85%, Val Loss: 0.6857, Val Accuracy: 70.96%\n",
      "Epoch [31/50], Train Loss: 0.4255, Train Accuracy: 82.23%, Val Loss: 0.6688, Val Accuracy: 71.69%\n",
      "Epoch [32/50], Train Loss: 0.4382, Train Accuracy: 82.87%, Val Loss: 0.7144, Val Accuracy: 72.06%\n",
      "Epoch [33/50], Train Loss: 0.3906, Train Accuracy: 84.62%, Val Loss: 0.6743, Val Accuracy: 72.06%\n",
      "Epoch [34/50], Train Loss: 0.3692, Train Accuracy: 83.89%, Val Loss: 0.6925, Val Accuracy: 72.79%\n",
      "Epoch [35/50], Train Loss: 0.4025, Train Accuracy: 83.33%, Val Loss: 0.6976, Val Accuracy: 70.22%\n",
      "Epoch [36/50], Train Loss: 0.3980, Train Accuracy: 82.87%, Val Loss: 0.6873, Val Accuracy: 70.22%\n",
      "Epoch [37/50], Train Loss: 0.3695, Train Accuracy: 84.90%, Val Loss: 0.6872, Val Accuracy: 70.96%\n",
      "Epoch [38/50], Train Loss: 0.3966, Train Accuracy: 83.43%, Val Loss: 0.7082, Val Accuracy: 71.32%\n",
      "Epoch [39/50], Train Loss: 0.3691, Train Accuracy: 84.62%, Val Loss: 0.6333, Val Accuracy: 76.47%\n",
      "Epoch [40/50], Train Loss: 0.3485, Train Accuracy: 86.37%, Val Loss: 0.6899, Val Accuracy: 70.96%\n",
      "Epoch [41/50], Train Loss: 0.3700, Train Accuracy: 84.35%, Val Loss: 0.6863, Val Accuracy: 70.96%\n",
      "Epoch [42/50], Train Loss: 0.3293, Train Accuracy: 87.57%, Val Loss: 0.6953, Val Accuracy: 73.90%\n",
      "Epoch [43/50], Train Loss: 0.3433, Train Accuracy: 86.74%, Val Loss: 0.7800, Val Accuracy: 72.43%\n",
      "Epoch [44/50], Train Loss: 0.3546, Train Accuracy: 85.27%, Val Loss: 0.7424, Val Accuracy: 71.32%\n",
      "Epoch [45/50], Train Loss: 0.3305, Train Accuracy: 87.85%, Val Loss: 0.7705, Val Accuracy: 71.32%\n",
      "Epoch [46/50], Train Loss: 0.3256, Train Accuracy: 86.65%, Val Loss: 0.7561, Val Accuracy: 72.43%\n",
      "Epoch [47/50], Train Loss: 0.3147, Train Accuracy: 87.11%, Val Loss: 0.7483, Val Accuracy: 70.59%\n",
      "Epoch [48/50], Train Loss: 0.3096, Train Accuracy: 88.03%, Val Loss: 0.7801, Val Accuracy: 69.12%\n",
      "Epoch [49/50], Train Loss: 0.3143, Train Accuracy: 86.74%, Val Loss: 0.7635, Val Accuracy: 70.96%\n",
      "Epoch [50/50], Train Loss: 0.2887, Train Accuracy: 88.21%, Val Loss: 0.7787, Val Accuracy: 72.43%\n",
      "\n",
      "Оценка модели на тестовой выборке...\n",
      "\n",
      "Test Accuracy: 0.7243\n",
      "\n",
      "Обучение завершено за 1.29 секунд\n",
      "Результаты сохранены в model_training_results\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessMoveDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.labels = torch.LongTensor(labels.values if hasattr(labels, 'values') else labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessMoveNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.2):\n",
    "        super(ChessMoveNetwork, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(hidden_size),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        layers.append(nn.Linear(prev_size, output_size))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(base_path=\"neural_network_figures\"):\n",
    "    output_dir = Path(base_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Создана директория для графиков: {output_dir.absolute()}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Загрузка и подготовка данных для обучения\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('preprocessed_data/processed_chess_data.csv')\n",
    "    features = ['pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff',\n",
    "               'material_value', 'center_control', 'extended_center_control', 'mobility_diff',\n",
    "               'king_safety_diff', 'development_diff', 'pawn_structure_diff', 'piece_square_diff',\n",
    "               'square_control', 'game_phase', 'tempo', 'white_mobility', 'black_mobility',\n",
    "               'white_king_safety', 'black_king_safety', 'white_development', 'black_development',\n",
    "               'white_pawn_structure', 'black_pawn_structure', 'white_piece_square', 'black_piece_square']\n",
    "    \n",
    "    available_features = [f for f in features if f in df.columns]\n",
    "    if len(available_features) != len(features):\n",
    "        print(f\"Внимание: Доступно только {len(available_features)} из {len(features)} признаков\")\n",
    "        features = available_features\n",
    "    \n",
    "    X = df[features]\n",
    "    y = df['result'].map({-1: 0, 0: 1, 1: 2})\n",
    "    \n",
    "    print(f\"Размерность признаков: {X.shape}\")\n",
    "    print(f\"Количество признаков: {len(features)}\")\n",
    "    \n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network_architecture(X_train, y_train, device):\n",
    "    print(\"\\n=== Оптимизация архитектуры нейронной сети ===\")\n",
    "    input_size = X_train.shape[1]\n",
    "    print(f\"Размер входного слоя: {input_size}\")\n",
    "    \n",
    "    architectures = [\n",
    "        {'hidden_sizes': [128, 64], 'dropout_rate': 0.2},\n",
    "        {'hidden_sizes': [256, 128, 64], 'dropout_rate': 0.2},\n",
    "        {'hidden_sizes': [512, 256, 128, 64], 'dropout_rate': 0.3},\n",
    "        {'hidden_sizes': [256, 256, 128, 128, 64], 'dropout_rate': 0.25}\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for arch in architectures:\n",
    "        print(f\"\\nТестирование архитектуры: {arch['hidden_sizes']}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model = ChessMoveNetwork(\n",
    "            input_size=input_size,\n",
    "            hidden_sizes=arch['hidden_sizes'],\n",
    "            output_size=3,\n",
    "            dropout_rate=arch['dropout_rate']\n",
    "        ).to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        train_dataset = ChessMoveDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        \n",
    "        model.train()\n",
    "        for epoch in range(10):  \n",
    "            for features, labels in train_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            features = torch.FloatTensor(X_train).to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_train_tensor = torch.LongTensor(y_train.values if hasattr(y_train, 'values') else y_train)\n",
    "            accuracy = (predicted.cpu() == y_train_tensor).sum().item() / len(y_train)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        results.append({\n",
    "            'Архитектура': str(arch['hidden_sizes']),\n",
    "            'Dropout': arch['dropout_rate'],\n",
    "            'Точность': accuracy,\n",
    "            'Время обучения (с)': training_time\n",
    "        })\n",
    "        \n",
    "        print(f\"Точность: {accuracy:.4f}\")\n",
    "        print(f\"Время обучения: {training_time:.2f} секунд\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_optimization_results(results_df, output_dir):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=results_df, x='Архитектура', y='Точность')\n",
    "    plt.title('Сравнение точности различных архитектур')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'architecture_accuracy_comparison.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=results_df, x='Архитектура', y='Время обучения (с)')\n",
    "    plt.title('Сравнение времени обучения различных архитектур')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'architecture_training_time_comparison.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало процесса оптимизации нейронной сети...\n",
      "Используется устройство: cpu\n",
      "Размерность признаков: (1358, 26)\n",
      "Количество признаков: 26\n",
      "\n",
      "=== Оптимизация архитектуры нейронной сети ===\n",
      "Размер входного слоя: 26\n",
      "\n",
      "Тестирование архитектуры: [128, 64]\n",
      "Точность: 0.7339\n",
      "Время обучения: 0.16 секунд\n",
      "\n",
      "Тестирование архитектуры: [256, 128, 64]\n",
      "Точность: 0.7983\n",
      "Время обучения: 0.22 секунд\n",
      "\n",
      "Тестирование архитектуры: [512, 256, 128, 64]\n",
      "Точность: 0.7680\n",
      "Время обучения: 0.35 секунд\n",
      "\n",
      "Тестирование архитектуры: [256, 256, 128, 128, 64]\n",
      "Точность: 0.7753\n",
      "Время обучения: 0.36 секунд\n",
      "Создана директория для графиков: /Users/skolkoff/Desktop/StoneS_ЭП/neural_network_figures\n",
      "\n",
      "Результаты сохранены в 'neural_network_optimization_results.csv'\n",
      "Все графики сохранены.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Начало процесса оптимизации нейронной сети...\")\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Используется устройство: {device}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = load_data()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    results_df = optimize_network_architecture(X_train, y_train, device)\n",
    "    \n",
    "    output_dir = create_output_directory()\n",
    "    visualize_optimization_results(results_df, output_dir)\n",
    "    \n",
    "    results_df.to_csv('neural_network_optimization_results.csv', index=False)\n",
    "    print(\"\\nРезультаты сохранены в 'neural_network_optimization_results.csv'\")\n",
    "    print(\"Все графики сохранены.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detailed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(base_path=\"detailed_figures\"):\n",
    "    \"\"\"\n",
    "    Создание директории для сохранения графиков\n",
    "    \"\"\"\n",
    "    output_dir = Path(base_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Создана директория для графиков: {output_dir.absolute()}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Загрузка предобработанных данных\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_path = Path('preprocessed_data/processed_chess_data.csv')\n",
    "        if data_path.exists():\n",
    "            return pd.read_csv(data_path)\n",
    "        \n",
    "        data_path = Path('processed_chess_data.csv')\n",
    "        if data_path.exists():\n",
    "            return pd.read_csv(data_path)\n",
    "            \n",
    "        raise FileNotFoundError(\"Файл с данными не найден. Убедитесь, что файл processed_chess_data.csv существует в директории preprocessed_data/ или в корневой директории.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistical_analysis(df, output_dir):\n",
    "    \"\"\"\n",
    "    Выполнение статистического анализа\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Статистический анализ ===\")\n",
    "    print(\"\\nДоступные столбцы в данных:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    numeric_features = ['pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff',\n",
    "                       'material_value', 'center_control', 'extended_center_control', 'mobility_diff',\n",
    "                       'king_safety_diff', 'development_diff', 'pawn_structure_diff', 'piece_square_diff',\n",
    "                       'square_control', 'game_phase', 'tempo', 'white_mobility', 'black_mobility',\n",
    "                       'white_king_safety', 'black_king_safety', 'white_development', 'black_development',\n",
    "                       'white_pawn_structure', 'black_pawn_structure', 'white_piece_square', 'black_piece_square']\n",
    "    \n",
    "    available_features = [f for f in numeric_features if f in df.columns]\n",
    "    if len(available_features) != len(numeric_features):\n",
    "        print(f\"Внимание: Доступно только {len(available_features)} из {len(numeric_features)} признаков\")\n",
    "        print(f\"Недостающие признаки: {set(numeric_features) - set(available_features)}\")\n",
    "        numeric_features = available_features\n",
    "    \n",
    "    correlation_matrix = df[numeric_features].corr()\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Корреляционная матрица числовых признаков')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'correlation_matrix_detailed.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(data=df, x=feature, bins=50)\n",
    "        plt.title(f'Распределение {feature}')\n",
    "        plt.savefig(output_dir / f'distribution_{feature}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    if 'mobility_diff' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='result', y='mobility_diff')\n",
    "        plt.title('Распределение разности мобильности по результатам игр')\n",
    "        plt.savefig(output_dir / 'mobility_by_result.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    if 'center_control' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='result', y='center_control')\n",
    "        plt.title('Распределение контроля центра по результатам игр')\n",
    "        plt.savefig(output_dir / 'center_control_by_result.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    if 'material_value' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='result', y='material_value')\n",
    "        plt.title('Распределение материального преимущества по результатам игр')\n",
    "        plt.savefig(output_dir / 'material_value_by_result.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    if 'king_safety_diff' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=df, x='result', y='king_safety_diff')\n",
    "        plt.title('Распределение безопасности короля по результатам игр')\n",
    "        plt.savefig(output_dir / 'king_safety_by_result.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_pca_analysis(df, output_dir):\n",
    "    \"\"\"\n",
    "    Выполнение анализа главных компонент\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Анализ главных компонент ===\")\n",
    "    \n",
    "    features = ['pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff',\n",
    "                'material_value', 'center_control', 'extended_center_control', 'mobility_diff',\n",
    "                'king_safety_diff', 'development_diff', 'pawn_structure_diff', 'piece_square_diff',\n",
    "                'square_control', 'tempo', 'white_mobility', 'black_mobility',\n",
    "                'white_king_safety', 'black_king_safety', 'white_development', 'black_development',\n",
    "                'white_pawn_structure', 'black_pawn_structure', 'white_piece_square', 'black_piece_square']\n",
    "    \n",
    "    available_features = []\n",
    "    for f in features:\n",
    "        if f in df.columns and df[f].dtype in ['int64', 'float64']:\n",
    "            available_features.append(f)\n",
    "    \n",
    "    if len(available_features) != len(features):\n",
    "        print(f\"Внимание: Доступно только {len(available_features)} числовых признаков из {len(features)}\")\n",
    "        features = available_features\n",
    "    \n",
    "    X = df[features]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(pca.explained_variance_ratio_) + 1),\n",
    "             np.cumsum(pca.explained_variance_ratio_), 'bo-')\n",
    "    plt.xlabel('Количество компонент')\n",
    "    plt.ylabel('Накопленная объясненная дисперсия')\n",
    "    plt.title('Накопленная объясненная дисперсия по компонентам')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(output_dir / 'pca_explained_variance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.5)\n",
    "    plt.xlabel('Первая главная компонента')\n",
    "    plt.ylabel('Вторая главная компонента')\n",
    "    plt.title('Проекция данных на первые две главные компоненты')\n",
    "    plt.savefig(output_dir / 'pca_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    feature_importance = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        columns=[f'PC{i+1}' for i in range(len(features))],\n",
    "        index=features\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(feature_importance, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Вклад признаков в главные компоненты')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'pca_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detailed_report(df, feature_importance, output_dir):\n",
    "    \"\"\"\n",
    "    Генерация детального отчета\n",
    "    \"\"\"\n",
    "    with open(output_dir / 'detailed_analysis_report.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Детальный анализ шахматных данных\\n\")\n",
    "        f.write(\"==============================\\n\\n\")\n",
    "        \n",
    "        f.write(\"1. Общая информация о датасете\\n\")\n",
    "        f.write(\"---------------------------\\n\")\n",
    "        f.write(f\"Количество позиций: {len(df)}\\n\")\n",
    "        f.write(f\"Количество признаков: {len(df.columns)}\\n\")\n",
    "        f.write(f\"Список признаков: {', '.join(df.columns)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"2. Распределение результатов\\n\")\n",
    "        f.write(\"-------------------------\\n\")\n",
    "        f.write(df['result'].value_counts().to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"3. Статистические характеристики\\n\")\n",
    "        f.write(\"-----------------------------\\n\")\n",
    "        f.write(df.describe().to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"4. Вклад признаков в главные компоненты\\n\")\n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        f.write(feature_importance.to_string())\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        f.write(\"5. Корреляции между признаками\\n\")\n",
    "        f.write(\"---------------------------\\n\")\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        exclude_columns = ['result', 'game_id', 'move_number', 'white_elo', 'black_elo']\n",
    "        numeric_features = [col for col in numeric_columns if col not in exclude_columns]\n",
    "        \n",
    "        if numeric_features:\n",
    "            f.write(df[numeric_features].corr().to_string())\n",
    "        else:\n",
    "            f.write(\"Числовые признаки не найдены\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Начало детального анализа...\")\n",
    "    \n",
    "    output_dir = create_output_directory(\"detailed_analysis_results\")\n",
    "    \n",
    "    try:\n",
    "        print(\"Загрузка данных...\")\n",
    "        df = load_data()\n",
    "        print(f\"Загружено {len(df)} строк данных\")\n",
    "        print(\"\\nВыполнение статистического анализа...\")\n",
    "        perform_statistical_analysis(df, output_dir)\n",
    "        print(\"\\nВыполнение PCA анализа...\")\n",
    "        feature_importance = perform_pca_analysis(df, output_dir)\n",
    "        print(\"\\nГенерация отчета...\")\n",
    "        generate_detailed_report(df, feature_importance, output_dir)\n",
    "        \n",
    "        print(f\"\\nАнализ завершен. Все результаты сохранены в директории: {output_dir.absolute()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nОшибка при выполнении анализа: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало детального анализа...\n",
      "Создана директория для графиков: /Users/skolkoff/Desktop/StoneS_ЭП/detailed_analysis_results\n",
      "Загрузка данных...\n",
      "Загружено 1358 строк данных\n",
      "\n",
      "Выполнение статистического анализа...\n",
      "\n",
      "=== Статистический анализ ===\n",
      "\n",
      "Доступные столбцы в данных:\n",
      "['pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff', 'material_value', 'center_control', 'extended_center_control', 'mobility_diff', 'king_safety_diff', 'development_diff', 'pawn_structure_diff', 'piece_square_diff', 'square_control', 'game_phase', 'tempo', 'white_mobility', 'black_mobility', 'white_king_safety', 'black_king_safety', 'white_development', 'black_development', 'white_pawn_structure', 'black_pawn_structure', 'white_piece_square', 'black_piece_square', 'result', 'game_id', 'move_number', 'white_elo', 'black_elo', 'game_phase.1']\n",
      "\n",
      "Выполнение PCA анализа...\n",
      "\n",
      "=== Анализ главных компонент ===\n",
      "\n",
      "Генерация отчета...\n",
      "\n",
      "Анализ завершен. Все результаты сохранены в директории: /Users/skolkoff/Desktop/StoneS_ЭП/detailed_analysis_results\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс для работы с данными шахматных партий\n",
    "    \"\"\"\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        labels_array = labels.values if hasattr(labels, 'values') else labels\n",
    "        self.labels = torch.LongTensor(labels_array.astype(np.int64))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedChessNeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Улучшенная нейронная сеть для анализа шахматных партий\n",
    "    Упрощенная архитектура для предотвращения переобучения\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, output_size, dropout_rate=0.4):\n",
    "        super(ImprovedChessNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, max(32, input_size + 8)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            \n",
    "            nn.Linear(max(32, input_size + 8), 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate * 0.7),  \n",
    "            \n",
    "            nn.Linear(24, output_size)\n",
    "        )\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Инициализация весов для лучшей сходимости\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping для предотвращения переобучения\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "        self.early_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_output_directory(base_path=\"neural_network_results\"):\n",
    "    \"\"\"\n",
    "    Создание директории для сохранения результатов\n",
    "    \"\"\"\n",
    "    output_dir = Path(base_path)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Создана директория для результатов: {output_dir.absolute()}\")\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    \"\"\"\n",
    "    Загрузка и подготовка данных для обучения\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv('preprocessed_data/processed_chess_data.csv')\n",
    "        print(f\"Загружено {len(df)} строк данных\")\n",
    "        \n",
    "        features = ['pawn_diff', 'knight_diff', 'bishop_diff', 'rook_diff', 'queen_diff',\n",
    "                   'material_value', 'center_control', 'extended_center_control', 'mobility_diff',\n",
    "                   'king_safety_diff', 'development_diff', 'pawn_structure_diff', 'piece_square_diff',\n",
    "                   'square_control', 'game_phase', 'tempo', 'white_mobility', 'black_mobility',\n",
    "                   'white_king_safety', 'black_king_safety', 'white_development', 'black_development',\n",
    "                   'white_pawn_structure', 'black_pawn_structure', 'white_piece_square', 'black_piece_square']\n",
    "        \n",
    "        available_features = [f for f in features if f in df.columns]\n",
    "        if len(available_features) != len(features):\n",
    "            print(f\"Внимание: Доступно только {len(available_features)} из {len(features)} признаков\")\n",
    "            print(f\"Недостающие признаки: {set(features) - set(available_features)}\")\n",
    "        \n",
    "        X = df[available_features]\n",
    "        y = df['result'].map({-1: 0, 0: 1, 1: 2})\n",
    "        print(f\"Размерность признаков: {X.shape}\")\n",
    "        print(f\"Размерность целевой переменной: {y.shape}\")\n",
    "        \n",
    "        from sklearn.utils import resample\n",
    "        \n",
    "        df_class_0 = df[y == 0]  \n",
    "        df_class_1 = df[y == 1]  \n",
    "        df_class_2 = df[y == 2]  \n",
    "        \n",
    "        print(f\"Распределение классов до балансировки:\")\n",
    "        print(f\"Победы черных: {len(df_class_0)}\")\n",
    "        print(f\"Ничьи: {len(df_class_1)}\")\n",
    "        print(f\"Победы белых: {len(df_class_2)}\")\n",
    "        \n",
    "        min_class_size = min(len(df_class_0), len(df_class_1), len(df_class_2))\n",
    "        target_size = min(min_class_size, 5000)  \n",
    "        \n",
    "        df_class_0_balanced = resample(df_class_0, n_samples=target_size, random_state=42)\n",
    "        df_class_1_balanced = resample(df_class_1, n_samples=target_size, random_state=42)\n",
    "        df_class_2_balanced = resample(df_class_2, n_samples=target_size, random_state=42)\n",
    "        df_balanced = pd.concat([df_class_0_balanced, df_class_1_balanced, df_class_2_balanced])\n",
    "        \n",
    "        X = df_balanced[available_features]\n",
    "        y = df_balanced['result'].map({-1: 0, 0: 1, 1: 2})\n",
    "        \n",
    "        print(f\"Размер после балансировки: {X.shape}\")\n",
    "        print(f\"Распределение классов после балансировки:\")\n",
    "        print(y.value_counts().sort_index())\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "        print(f\"Размер тестовой выборки: {X_test.shape}\")\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                num_epochs, device, output_dir):\n",
    "    \"\"\"\n",
    "    Обучение модели с early stopping и адаптивным learning rate\n",
    "    \"\"\"\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    best_val_accuracy = 0\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_accuracy = 100 * train_correct / train_total\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), output_dir / 'best_model.pth')\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "              f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        early_stopping(val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping на эпохе {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(train_losses, val_losses, train_accuracies, \n",
    "                             val_accuracies, output_dir):\n",
    "    \"\"\"\n",
    "    Визуализация результатов обучения\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss', alpha=0.8)\n",
    "    plt.plot(val_losses, label='Validation Loss', alpha=0.8)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Accuracy', alpha=0.8)\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy', alpha=0.8)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'training_plots.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_network_performance(model, test_loader, device, output_dir):\n",
    "    \"\"\"\n",
    "    Подробный анализ производительности сети\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features = features.to(device)\n",
    "            outputs = model(features)\n",
    "            probabilities = torch.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    \n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Черные побеждают', 'Ничья', 'Белые побеждают'],\n",
    "                yticklabels=['Черные побеждают', 'Ничья', 'Белые побеждают'])\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Фактический результат')\n",
    "    plt.xlabel('Предсказанный результат')\n",
    "    plt.savefig(output_dir / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    accuracy = np.mean(np.array(all_predictions) == np.array(all_labels))\n",
    "    report = classification_report(all_labels, all_predictions, \n",
    "                                 target_names=['Черные побеждают', 'Ничья', 'Белые побеждают'])\n",
    "    \n",
    "    print(f\"\\nFinal Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    probabilities = np.array(all_probabilities)\n",
    "    max_probs = np.max(probabilities, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(max_probs, bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Максимальная вероятность предсказания')\n",
    "    plt.ylabel('Количество предсказаний')\n",
    "    plt.title('Распределение уверенности модели в предсказаниях')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(output_dir / 'confidence_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    output_dir = create_output_directory()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = load_and_prepare_data()\n",
    "    input_size = X_train.shape[1]\n",
    "    output_size = 3\n",
    "    batch_size = 64  \n",
    "    num_epochs = 50  \n",
    "    learning_rate = 0.01  \n",
    "    dropout_rate = 0.2  \n",
    "    \n",
    "    print(f\"Размер входного слоя: {input_size}\")\n",
    "    print(f\"Упрощенная архитектура: {input_size} -> {max(32, input_size + 8)} -> 24 -> {output_size}\")\n",
    "    \n",
    "    train_dataset = ChessDataset(X_train, y_train)\n",
    "    test_dataset = ChessDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model = ImprovedChessNeuralNetwork(input_size, output_size, dropout_rate)\n",
    "    model = model.to(device)\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    \n",
    "    unique_classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight('balanced', classes=unique_classes, y=y_train)\n",
    "    class_weights = np.power(class_weights, 0.7)  \n",
    "    class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "    \n",
    "    print(f\"Веса классов (смягченные): {class_weights}\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.7, \n",
    "                                                    patience=5)\n",
    "    \n",
    "    print(\"\\nНачало обучения улучшенной модели...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_losses, val_losses, train_accuracies, val_accuracies = train_model(\n",
    "        model, train_loader, test_loader, criterion, optimizer, scheduler,\n",
    "        num_epochs, device, output_dir\n",
    "    )\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nОбучение завершено за {training_time:.2f} секунд\")\n",
    "\n",
    "    model.load_state_dict(torch.load(output_dir / 'best_model.pth'))\n",
    "    visualize_training_results(\n",
    "        train_losses, val_losses, train_accuracies, val_accuracies, output_dir\n",
    "    )\n",
    "    test_accuracy = analyze_network_performance(model, test_loader, device, output_dir)\n",
    "    \n",
    "    with open(output_dir / 'improved_model_info.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Улучшенная нейронная сеть - Отчет\\n\")\n",
    "        f.write(\"=================================\\n\\n\")\n",
    "        f.write(\" ПРИМЕНЕННЫЕ УЛУЧШЕНИЯ:\\n\")\n",
    "        f.write(\"1. Упрощенная архитектура для предотвращения переобучения\\n\")\n",
    "        f.write(\"2. Early stopping с patience=10\\n\")\n",
    "        f.write(\"3. Gradient clipping для стабильности\\n\")\n",
    "        f.write(\"4. Адаптивный learning rate scheduler\\n\")\n",
    "        f.write(\"5. Улучшенная балансировка данных\\n\")\n",
    "        f.write(\"6. Смягченные веса классов\\n\")\n",
    "        f.write(\"7. Инициализация весов Xavier\\n\\n\")\n",
    "        f.write(f\" АРХИТЕКТУРА:\\n\")\n",
    "        f.write(f\"- Входной слой: {input_size} нейронов\\n\")\n",
    "        f.write(f\"- Скрытый слой 1: {max(32, input_size + 8)} нейронов + ReLU + Dropout({dropout_rate})\\n\")\n",
    "        f.write(f\"- Скрытый слой 2: 24 нейрона + ReLU + Dropout({dropout_rate * 0.7:.2f})\\n\")\n",
    "        f.write(f\"- Выходной слой: {output_size} нейронов\\n\\n\")\n",
    "        f.write(f\"- ПАРАМЕТРЫ ОБУЧЕНИЯ:\\n\")\n",
    "        f.write(f\"- Batch size: {batch_size}\\n\")\n",
    "        f.write(f\"- Максимум эпох: {num_epochs}\\n\")\n",
    "        f.write(f\"- Learning rate: {learning_rate}\\n\")\n",
    "        f.write(f\"- Оптимизатор: Adam с weight_decay=1e-4\\n\")\n",
    "        f.write(f\"- Scheduler: ReduceLROnPlateau\\n\")\n",
    "        f.write(f\"- Функция потерь: CrossEntropyLoss со смягченными весами\\n\\n\")\n",
    "        f.write(f\"- РЕЗУЛЬТАТЫ:\\n\")\n",
    "        f.write(f\"- Время обучения: {training_time:.2f} секунд\\n\")\n",
    "        f.write(f\"- Количество эпох: {len(train_losses)}\\n\")\n",
    "        f.write(f\"- Лучшая валидационная точность: {max(val_accuracies):.2f}%\\n\")\n",
    "        f.write(f\"- Итоговая тестовая точность: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\\n\\n\")\n",
    "        f.write(f\"- ЦЕЛЬ: Превысить 70% точности\\n\")\n",
    "        f.write(f\"- Результат: {'ДОСТИГНУТА' if test_accuracy > 0.60 else 'НЕ ДОСТИГНУТА'}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создана директория для результатов: /Users/skolkoff/Desktop/StoneS_ЭП/neural_network_results\n",
      "Загружено 1358 строк данных\n",
      "Размерность признаков: (1358, 26)\n",
      "Размерность целевой переменной: (1358,)\n",
      "Распределение классов до балансировки:\n",
      "Победы черных: 446\n",
      "Ничьи: 456\n",
      "Победы белых: 456\n",
      "Размер после балансировки: (1338, 26)\n",
      "Распределение классов после балансировки:\n",
      "result\n",
      "0    446\n",
      "1    446\n",
      "2    446\n",
      "Name: count, dtype: int64\n",
      "Размер обучающей выборки: (1070, 26)\n",
      "Размер тестовой выборки: (268, 26)\n",
      "Размер входного слоя: 26\n",
      "Упрощенная архитектура: 26 -> 34 -> 24 -> 3\n",
      "Using device: cpu\n",
      "Веса классов (смягченные): [0.99934631 0.99934631 1.00131049]\n",
      "\n",
      "Начало обучения улучшенной модели...\n",
      "Epoch [1/50], Train Loss: 1.0924, Train Accuracy: 44.67%, Val Loss: 0.9688, Val Accuracy: 54.10%\n",
      "Epoch [2/50], Train Loss: 0.9814, Train Accuracy: 51.40%, Val Loss: 0.9432, Val Accuracy: 52.61%\n",
      "Epoch [3/50], Train Loss: 0.9223, Train Accuracy: 55.79%, Val Loss: 0.8883, Val Accuracy: 58.21%\n",
      "Epoch [4/50], Train Loss: 0.8822, Train Accuracy: 58.41%, Val Loss: 0.8556, Val Accuracy: 61.19%\n",
      "Epoch [5/50], Train Loss: 0.8448, Train Accuracy: 60.75%, Val Loss: 0.8175, Val Accuracy: 59.70%\n",
      "Epoch [6/50], Train Loss: 0.8291, Train Accuracy: 62.34%, Val Loss: 0.7992, Val Accuracy: 65.30%\n",
      "Epoch [7/50], Train Loss: 0.7961, Train Accuracy: 63.08%, Val Loss: 0.7947, Val Accuracy: 68.66%\n",
      "Epoch [8/50], Train Loss: 0.7773, Train Accuracy: 63.36%, Val Loss: 0.7912, Val Accuracy: 67.16%\n",
      "Epoch [9/50], Train Loss: 0.7405, Train Accuracy: 67.94%, Val Loss: 0.7828, Val Accuracy: 66.79%\n",
      "Epoch [10/50], Train Loss: 0.7368, Train Accuracy: 67.01%, Val Loss: 0.7594, Val Accuracy: 66.79%\n",
      "Epoch [11/50], Train Loss: 0.6942, Train Accuracy: 70.84%, Val Loss: 0.7279, Val Accuracy: 71.64%\n",
      "Epoch [12/50], Train Loss: 0.7004, Train Accuracy: 69.53%, Val Loss: 0.7236, Val Accuracy: 67.91%\n",
      "Epoch [13/50], Train Loss: 0.6585, Train Accuracy: 71.03%, Val Loss: 0.7201, Val Accuracy: 69.78%\n",
      "Epoch [14/50], Train Loss: 0.6542, Train Accuracy: 72.24%, Val Loss: 0.7040, Val Accuracy: 70.52%\n",
      "Epoch [15/50], Train Loss: 0.6437, Train Accuracy: 72.24%, Val Loss: 0.7312, Val Accuracy: 70.90%\n",
      "Epoch [16/50], Train Loss: 0.6381, Train Accuracy: 72.90%, Val Loss: 0.7212, Val Accuracy: 71.64%\n",
      "Epoch [17/50], Train Loss: 0.6288, Train Accuracy: 72.24%, Val Loss: 0.7370, Val Accuracy: 73.88%\n",
      "Epoch [18/50], Train Loss: 0.6316, Train Accuracy: 72.43%, Val Loss: 0.7075, Val Accuracy: 71.27%\n",
      "Epoch [19/50], Train Loss: 0.6122, Train Accuracy: 73.93%, Val Loss: 0.7261, Val Accuracy: 74.25%\n",
      "Epoch [20/50], Train Loss: 0.6023, Train Accuracy: 75.14%, Val Loss: 0.7099, Val Accuracy: 72.39%\n",
      "Epoch [21/50], Train Loss: 0.5887, Train Accuracy: 74.02%, Val Loss: 0.6868, Val Accuracy: 72.01%\n",
      "Epoch [22/50], Train Loss: 0.5647, Train Accuracy: 75.23%, Val Loss: 0.6904, Val Accuracy: 72.39%\n",
      "Epoch [23/50], Train Loss: 0.5702, Train Accuracy: 75.05%, Val Loss: 0.6927, Val Accuracy: 72.76%\n",
      "Epoch [24/50], Train Loss: 0.5665, Train Accuracy: 77.29%, Val Loss: 0.7168, Val Accuracy: 75.00%\n",
      "Epoch [25/50], Train Loss: 0.5533, Train Accuracy: 75.61%, Val Loss: 0.6944, Val Accuracy: 75.75%\n",
      "Epoch [26/50], Train Loss: 0.5375, Train Accuracy: 75.79%, Val Loss: 0.6554, Val Accuracy: 77.24%\n",
      "Epoch [27/50], Train Loss: 0.5348, Train Accuracy: 78.13%, Val Loss: 0.6850, Val Accuracy: 74.63%\n",
      "Epoch [28/50], Train Loss: 0.5270, Train Accuracy: 78.60%, Val Loss: 0.6657, Val Accuracy: 76.49%\n",
      "Epoch [29/50], Train Loss: 0.4867, Train Accuracy: 79.07%, Val Loss: 0.6631, Val Accuracy: 73.88%\n",
      "Epoch [30/50], Train Loss: 0.5085, Train Accuracy: 77.94%, Val Loss: 0.6751, Val Accuracy: 74.25%\n",
      "Epoch [31/50], Train Loss: 0.5107, Train Accuracy: 76.92%, Val Loss: 0.7082, Val Accuracy: 75.75%\n",
      "Epoch [32/50], Train Loss: 0.5410, Train Accuracy: 76.82%, Val Loss: 0.7055, Val Accuracy: 75.37%\n",
      "Epoch [33/50], Train Loss: 0.5104, Train Accuracy: 78.41%, Val Loss: 0.6969, Val Accuracy: 76.12%\n",
      "Epoch [34/50], Train Loss: 0.4842, Train Accuracy: 79.81%, Val Loss: 0.6734, Val Accuracy: 75.75%\n",
      "Epoch [35/50], Train Loss: 0.4867, Train Accuracy: 79.91%, Val Loss: 0.7053, Val Accuracy: 75.37%\n",
      "Epoch [36/50], Train Loss: 0.5066, Train Accuracy: 78.22%, Val Loss: 0.7070, Val Accuracy: 73.13%\n",
      "Early stopping на эпохе 36\n",
      "\n",
      "Обучение завершено за 0.52 секунд\n",
      "\n",
      "Final Test Accuracy: 0.7724 (77.24%)\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Черные побеждают       0.80      0.74      0.77        89\n",
      "           Ничья       0.73      0.78      0.75        89\n",
      " Белые побеждают       0.79      0.80      0.80        90\n",
      "\n",
      "        accuracy                           0.77       268\n",
      "       macro avg       0.77      0.77      0.77       268\n",
      "    weighted avg       0.77      0.77      0.77       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
